{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06371951",
   "metadata": {},
   "source": [
    "# Basic Classification NLP\n",
    "This is an example of a simple NLP classification using machine learning and a linear SVC model.\n",
    "\n",
    "In this example we will use an Amazon review dataset.\n",
    "\n",
    "First we will need to load the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf6525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "#import xlsxwriter as xlw\n",
    "import os\n",
    "import html\n",
    "import re\n",
    "#import seaborn as sb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import classification_report\n",
    "#from sklearn.metrics import ConfusionMatrixDisplay\n",
    "#from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "#from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import json\n",
    "import gzip\n",
    "#import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68af6e",
   "metadata": {},
   "source": [
    "Next, we'll load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ac492ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset found here http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Musical_Instruments_5.json.gz\n",
    "data = pd.read_json(\"C:\\\\Users\\\\kelvi\\\\Downloads\\\\reviews_Musical_Instruments_5.json.gz\", lines=True)\n",
    "\n",
    "# select the relevant categories for text from the data\n",
    "data = data[['reviewText', 'overall']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c791f11c",
   "metadata": {},
   "source": [
    "We'll create 2 custom functions below to use on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46153119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning function\n",
    "def clean(text):\n",
    "    # convert html escapes to characters\n",
    "    text = html.unescape(text)\n",
    "    # tags like <tab>\n",
    "    text = re.sub(r'<[^<>]*>', ' ', text)\n",
    "    # markdown URLs\n",
    "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
    "    # text in code or brackets\n",
    "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
    "    # standalone sequences of specials\n",
    "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text)\n",
    "    # standalone sequences of hyphens\n",
    "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text)\n",
    "    # sequences of whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # make lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# make a custom function which says whether a rating is positive or negative\n",
    "def review_rating(value):\n",
    "    if value['overall'] > 3: # a rating of 4 stars or more is viewed as \"positive\"\n",
    "        return \"positive\"\n",
    "    elif value['overall'] < 3:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"remove me!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650ab53d",
   "metadata": {},
   "source": [
    "Let's apply these functions to our data and do some filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e44f543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviewText'] = data['reviewText'].apply(clean)\n",
    "\n",
    "data['type'] = data.apply(review_rating,axis=1)\n",
    "\n",
    "# we'll remove the 3 star removes as they're not very helpful to say without investigation as to whether it is positive or negative\n",
    "data = data[data['type']!=\"remove me!\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d3ef25",
   "metadata": {},
   "source": [
    "Next, we'll examine the dataset and adjust it if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4861cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get a breakdown of our dataset so we know how it is comprised\n",
    "type_counts = data['type'].value_counts()\n",
    "\n",
    "# this is quite one-sided, let's remove most of the positive to make the dataset more even\n",
    "data_pos = data[data['type']==\"positive\"]\n",
    "data_neg = data[data['type']==\"negative\"]\n",
    "\n",
    "data_pos = data_pos[1:800]\n",
    "\n",
    "data = pd.concat([data_pos,data_neg],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812d7ef",
   "metadata": {},
   "source": [
    "Get the data ready for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffe0fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "############# set X and y variables for model\n",
    "y = data['type']\n",
    "#yvalue='chk_Hot' # for graph\n",
    "X = data['reviewText']# must be single brackets for tdidf #pd.get_dummies(df)\n",
    "\n",
    "sample = 0.3 #size of test dataset\n",
    "\n",
    "#default train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=sample,random_state=42,stratify=y,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f91eca",
   "metadata": {},
   "source": [
    "Configure the linearsvc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8d49143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "model = LinearSVC(random_state=42, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "347ec1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data pipeline\n",
    "training_pipeline = Pipeline(\n",
    "    steps=[('tfidf', TfidfVectorizer(stop_words=\"english\")), ('model', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2371a4e3",
   "metadata": {},
   "source": [
    "How does this model score without any hyperparameter adjustments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0e8997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8193922736295617"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score = cross_val_score(training_pipeline, X_train, y_train,cv=3)\n",
    "model_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2566fabb",
   "metadata": {},
   "source": [
    "Can we improve on this score if we adjust any hyperparameter values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be51a02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['memory', 'steps', 'verbose', 'tfidf', 'model', 'tfidf__analyzer', 'tfidf__binary', 'tfidf__decode_error', 'tfidf__dtype', 'tfidf__encoding', 'tfidf__input', 'tfidf__lowercase', 'tfidf__max_df', 'tfidf__max_features', 'tfidf__min_df', 'tfidf__ngram_range', 'tfidf__norm', 'tfidf__preprocessor', 'tfidf__smooth_idf', 'tfidf__stop_words', 'tfidf__strip_accents', 'tfidf__sublinear_tf', 'tfidf__token_pattern', 'tfidf__tokenizer', 'tfidf__use_idf', 'tfidf__vocabulary', 'model__C', 'model__class_weight', 'model__dual', 'model__fit_intercept', 'model__intercept_scaling', 'model__loss', 'model__max_iter', 'model__multi_class', 'model__penalty', 'model__random_state', 'model__tol', 'model__verbose'])\n"
     ]
    }
   ],
   "source": [
    "# get a list of what we can alter in the param grid\n",
    "print(training_pipeline.get_params().keys())\n",
    "\n",
    "# adjust some of these here\n",
    "grid_param = {\n",
    "    'tfidf__min_df': [1,3,5,7],\n",
    "    'tfidf__ngram_range': [(1,2),(1,3),(1,5),(1,6),(1,9)],\n",
    "    'model__C': [1,2,3,4,5],\n",
    "    'model__loss': ['hinge']\n",
    "    #'model__kernel': ['linear']\n",
    "    }\n",
    "        \n",
    "\n",
    "gridSearchProcessor = GridSearchCV(estimator=training_pipeline,\n",
    "                                   param_grid=grid_param,\n",
    "                                   cv=10)\n",
    "\n",
    "gridSearchProcessor.fit(X_train,y_train)\n",
    "\n",
    "best_model_type = gridSearchProcessor.best_params_\n",
    "\n",
    "best_model_score = gridSearchProcessor.best_score_\n",
    "\n",
    "best_model = gridSearchProcessor.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9309130c",
   "metadata": {},
   "source": [
    "And the score is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9043b2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8453524004085802\n"
     ]
    }
   ],
   "source": [
    "print(best_model_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4113f18a",
   "metadata": {},
   "source": [
    "This is a slight improvement on the default model score. Let's take a look at generating some predictions and see any that are correct/incorrect to see if we can determine why the model may have predicted as it did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c5242de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new prediction dataset\n",
    "Xtest1 = data['reviewText']\n",
    "\n",
    "# this has already been cleaned otherwise we would apply the clean function again\n",
    "\n",
    "# generate new predictions using the best model (on the same dataset and we can see how it did)\n",
    "\n",
    "preds = best_model.predict(Xtest1)\n",
    "df = pd.DataFrame(data)\n",
    "df1 = pd.DataFrame(preds)\n",
    "\n",
    "#df = pd.merge(df,df1,how = 'left',left_index = True, right_index = True)\n",
    "df1.index=df.index\n",
    "df = pd.concat([df,df1],axis=1) # slab two columns together 0 means rows\n",
    "df.rename(columns={0:'type_pred'},inplace=True)\n",
    "\n",
    "# let's focus on the reviews that were incorrectly predicted and see if we can determine why\n",
    "df_err = df[df['type']!=df['type_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "795133ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>type</th>\n",
       "      <th>type_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fender cords look great and work just as well....</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>zero issues with this cable so far. it feels f...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>i bought this because i wanted a cheap replace...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>only complaint is the size which is my fault. ...</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reviewText  overall      type  \\\n",
       "19  fender cords look great and work just as well....        5  positive   \n",
       "42  zero issues with this cable so far. it feels f...        5  positive   \n",
       "44  i bought this because i wanted a cheap replace...        5  positive   \n",
       "79  only complaint is the size which is my fault. ...        4  positive   \n",
       "\n",
       "   type_pred  \n",
       "19  negative  \n",
       "42  negative  \n",
       "44  negative  \n",
       "79  negative  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view a sample of negative\n",
    "df_err_neg = df_err[df_err['type']==\"positive\"][1:5]\n",
    "df_err_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9539f9ea",
   "metadata": {},
   "source": [
    "For line 79, \"complaint\" could be viewed as a negative\n",
    "For line 44, \"cheap\" could be viewed positively or negatively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e8eca98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>type</th>\n",
       "      <th>type_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>the handle and spring strength make this uncom...</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>it's good but think its a bit expensive for ju...</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>the epiphone les paul guitars don't particular...</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>from greg abrams review, entitled \"for all but...</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reviewText  overall      type  \\\n",
       "286  the handle and spring strength make this uncom...        2  negative   \n",
       "335  it's good but think its a bit expensive for ju...        2  negative   \n",
       "376  the epiphone les paul guitars don't particular...        2  negative   \n",
       "412  from greg abrams review, entitled \"for all but...        2  negative   \n",
       "\n",
       "    type_pred  \n",
       "286  positive  \n",
       "335  positive  \n",
       "376  positive  \n",
       "412  positive  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view a sample of positive\n",
    "df_err_pos = df_err[df_err['type']==\"negative\"][1:5]\n",
    "df_err_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50425b4c",
   "metadata": {},
   "source": [
    "Line 335 features \"good\", which could mean the review is deemed positive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c037bef3",
   "metadata": {},
   "source": [
    "# Basic recommender system\n",
    "\n",
    "This is an example of a basic recommender system.\n",
    "\n",
    "Load the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bce1d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import html\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6883f2",
   "metadata": {},
   "source": [
    "Define some functions for use later in the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de4ef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a text cleaning function to column reviewText\n",
    "def clean(text):\n",
    "    # convert html escapes to characters\n",
    "    text = html.unescape(text)\n",
    "    # tags like <tab>\n",
    "    text = re.sub(r'<[^<>]*>', ' ', text)\n",
    "    # markdown URLs\n",
    "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
    "    # text in code or brackets\n",
    "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
    "    # standalone sequences of specials\n",
    "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text)\n",
    "    # standalone sequences of hyphens\n",
    "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text)\n",
    "    # sequences of whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # make lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# define the recommender system process\n",
    "def get_recommendations(title, cosine_sim, indices):\n",
    "        global res\n",
    "        # Get the index of the movie that matches the title\n",
    "        idx = indices[t]\n",
    "        # Get the pairwsie similarity scores\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        # Sort the movies based on the similarity scores\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        # Get the scores for 10 most similar movies\n",
    "        sim_scores = sim_scores[0:11]\n",
    "        # Get the movie indices\n",
    "        movie_indices = [i[0] for i in sim_scores]\n",
    "        # Return the top 10 most similar movies\n",
    "        res = data['reviewText'].iloc[movie_indices]\n",
    "        # make dataframe\n",
    "        res = res.to_frame().reset_index()\n",
    "        # get similarity scores\n",
    "        dff = pd.DataFrame(sim_scores)\n",
    "        dff.rename(columns={0:'index',1:'similarity'}, inplace=True)\n",
    "        # combine dataframes\n",
    "        res = pd.concat([res,dff], axis=1, ignore_index=True)\n",
    "        res.rename(columns={0:'index',1:'reviewText',2:'index1',3:'similarity'}, inplace=True)\n",
    "        res = res[['reviewText', 'similarity']]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0404ca",
   "metadata": {},
   "source": [
    "Load the data and process, vectorise it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8d1b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"C:\\\\Users\\\\kelvi\\\\Desktop\\\\reviews_Musical_Instruments_5.json.gz\", lines=True)\n",
    "\n",
    "# select the relevant categories for text and how we want to try and train NLP ml\n",
    "data = data[['reviewText', 'overall']]\n",
    "\n",
    "# clean the text data\n",
    "data['reviewText'] = data['reviewText'].apply(clean)\n",
    "\n",
    "# get indices\n",
    "indices = pd.Series(data.index, index=data['reviewText']).drop_duplicates()\n",
    "\n",
    "movie_plots = data['reviewText']\n",
    "\n",
    "# use tf-idf vectoriser\n",
    "tfidf = CountVectorizer(stop_words='english')#, max_features = 300) # irrespective of word occurences\n",
    "#tfidf = TfidfVectorizer(stop_words='english') # weight given to word occurences\n",
    "\n",
    "# Construct the TF-IDF matrix\n",
    "tfidf_matrix = tfidf.fit_transform(movie_plots)\n",
    "\n",
    "# to save space, we can dimensionally reduce the matrix\n",
    "np.random.seed(0)\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    " \n",
    "shrunk_matrix = TruncatedSVD(n_components=100).fit_transform(tfidf_matrix)\n",
    "\n",
    "# normalise the SVD output\n",
    "from sklearn.preprocessing import normalize\n",
    "shrunk_norm_matrix = normalize(shrunk_matrix)\n",
    "\n",
    "# save vectoriser\n",
    "#joblib.dump(tfidf_matrix,\"vec.pkl\")\n",
    "\n",
    "# load vectoriser\n",
    "#tfidf_matrix = joblib.load(\"vec.pkl\")\n",
    "\n",
    "# Generate the cosine similarity matrix - linear_kernel or cosine_similarity\n",
    "#cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix) \n",
    "#cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix) \n",
    "\n",
    "# cosine sim of shrunk matrix\n",
    "cosine_sim = shrunk_norm_matrix @ shrunk_norm_matrix.T\n",
    "\n",
    "# save cosine sim\n",
    "#joblib.dump(cosine_sim, \"sim_matrix.pkl\")\n",
    "\n",
    "# load cosine sim\n",
    "#cosine_sim = joblib.load(\"sim_matrix.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce93ba4",
   "metadata": {},
   "source": [
    "Next, create some phrase to use to search for in the reviews and then get top 10 reviews that are similar to this returned review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96717db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " linked to: great guitar\n",
      "                                           reviewText  similarity\n",
      "0   strings are not just strings. guitar strings a...    1.000000\n",
      "1   not very substantial. it began to tear on my g...    0.879715\n",
      "2   i bought a guitar and for a while used the str...    0.869009\n",
      "3   these strings are beyond amazing. switching to...    0.857657\n",
      "4   i'm primarily a guitar player, but i do have a...    0.853160\n",
      "5   these strings are a little more money than the...    0.849725\n",
      "6   i tried these strings on my zager guitar. the ...    0.840344\n",
      "7   sturdy, well-designed and frets the strings we...    0.837488\n",
      "8   these are the best guitar strings i have used ...    0.826279\n",
      "9   i am yet another one of those \"forever beginne...    0.820800\n",
      "10  these are great guitar strings and are all tha...    0.820313\n"
     ]
    }
   ],
   "source": [
    "chkr = \"great guitar\" # the phrase to search for\n",
    "chk = len(chkr)\n",
    "\n",
    "t = data['reviewText'].str.contains(chkr) # find if reviews contain this phrase - TRUE/FALSE\n",
    "t = t.to_frame() # make it a dataframe\n",
    "t = t[t['reviewText']==True] # filter to only those that are TRUE\n",
    "t = t.index[0] # return/keep only the first TRUE result\n",
    "\n",
    "# Generate recommendations\n",
    "print(\" linked to: \"+chkr)\n",
    "print(get_recommendations(chkr, cosine_sim, indices))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
